{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "90c5a325",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-12-30T20:52:55.488902Z",
          "iopub.status.busy": "2022-12-30T20:52:55.488463Z",
          "iopub.status.idle": "2022-12-30T20:53:47.951225Z",
          "shell.execute_reply": "2022-12-30T20:53:47.950103Z"
        },
        "papermill": {
          "duration": 52.47045,
          "end_time": "2022-12-30T20:53:47.953799",
          "exception": false,
          "start_time": "2022-12-30T20:52:55.483349",
          "status": "completed"
        },
        "tags": [],
        "id": "90c5a325",
        "outputId": "623e3076-330c-4435-dce8-2023b2ae8402"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -q timm\n",
        "!pip install -q git+https://github.com/PyFstat/PyFstat@python37"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f682ed3",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-12-30T20:53:47.961570Z",
          "iopub.status.busy": "2022-12-30T20:53:47.961257Z",
          "iopub.status.idle": "2022-12-30T20:53:51.748436Z",
          "shell.execute_reply": "2022-12-30T20:53:51.747444Z"
        },
        "papermill": {
          "duration": 3.79417,
          "end_time": "2022-12-30T20:53:51.751175",
          "exception": false,
          "start_time": "2022-12-30T20:53:47.957005",
          "status": "completed"
        },
        "tags": [],
        "id": "0f682ed3"
      },
      "outputs": [],
      "source": [
        "# import wandb\n",
        "import os, gc, re\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm.auto import tqdm\n",
        "import numpy as np, pandas as pd\n",
        "from collections import defaultdict\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "import timm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "\n",
        "import skimage\n",
        "from skimage import io\n",
        "\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "class CFG:\n",
        "    wandb=False\n",
        "    competition='G2Net'\n",
        "    model='inception_v4'\n",
        "    apex=False\n",
        "    max_grad_norm=1.36\n",
        "    seed=13\n",
        "    positive_rate=0.5\n",
        "    signal_low=0.2\n",
        "    signal_high=0.1\n",
        "    folds=10\n",
        "    lr=0.00056\n",
        "    dropout=0.25\n",
        "    epochs=3\n",
        "    gaussian_noise=2.\n",
        "    one_cycle_pct_start=0.1\n",
        "    one_cycle=True\n",
        "    batch=32\n",
        "    hog=True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b052d557",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-12-30T20:53:56.938003Z",
          "iopub.status.busy": "2022-12-30T20:53:56.937722Z",
          "iopub.status.idle": "2022-12-30T20:53:56.949578Z",
          "shell.execute_reply": "2022-12-30T20:53:56.948672Z"
        },
        "papermill": {
          "duration": 0.018516,
          "end_time": "2022-12-30T20:53:56.951695",
          "exception": false,
          "start_time": "2022-12-30T20:53:56.933179",
          "status": "completed"
        },
        "tags": [],
        "id": "b052d557"
      },
      "outputs": [],
      "source": [
        "def get_transforms():\n",
        "    return torchvision.transforms.Compose([\n",
        "            torchvision.transforms.ToTensor(),\n",
        "            torchvision.transforms.Normalize(mean=0.5, std=0.1)\n",
        "        ])\n",
        "\n",
        "def get_transforms_01():\n",
        "    return torchvision.transforms.Compose([\n",
        "        torchvision.transforms.ToTensor(),\n",
        "        torchvision.transforms.RandomChoice([\n",
        "            augment_time_mask,\n",
        "            augment_freq_mask,\n",
        "            torchvision.transforms.Lambda(lambda x: x)\n",
        "        ], p = [0.3, 0.3, 0.7]),\n",
        "        torchvision.transforms.Normalize(mean=0.5, std=0.1)\n",
        "        ])\n",
        "\n",
        "def get_transforms_02():\n",
        "    return torchvision.transforms.Compose([\n",
        "        torchvision.transforms.ToTensor(),\n",
        "        torchvision.transforms.RandomChoice([\n",
        "            augment_time_mask,\n",
        "            augment_freq_mask,\n",
        "            torchvision.transforms.Lambda(lambda x: x)\n",
        "        ], p = [0.5, 0.5, 0.5]),\n",
        "        torchvision.transforms.Normalize(mean=0.5, std=0.1)\n",
        "        ])\n",
        "\n",
        "def get_transforms_03():\n",
        "    return torchvision.transforms.Compose([\n",
        "        torchvision.transforms.ToTensor(),\n",
        "        torchvision.transforms.RandomChoice([\n",
        "            FlipWave(),\n",
        "            torchvision.transforms.Lambda(lambda x: x)\n",
        "        ], p = [0.5, 0.5]),\n",
        "        torchvision.transforms.Normalize(mean=0.5, std=0.1)\n",
        "        ])\n",
        "\n",
        "\n",
        "class G2Net_Dataset(nn.Dataset):\n",
        "    def __init__(\n",
        "        self,\n",
        "        df_noise: pd.DataFrame,\n",
        "        df_signal: pd.DataFrame,\n",
        "        positive_rate: float = CFG.positive_rate,\n",
        "        gaussian_noise: float = CFG.gaussian_noise,\n",
        "        signal_low: float = CFG.signal_low,\n",
        "        signal_high: float = CFG.signal_high\n",
        "        is_train: bool = False\n",
        "    ) -> None:\n",
        "        self.df_noise = df_noise\n",
        "        self.df_signal = df_signal\n",
        "        self.positive_rate = positive_rate\n",
        "        self.gaussian_noise = gaussian_noise\n",
        "        self.signal_low = signal_low\n",
        "        self.signal_high = signal_high\n",
        "        self.transforms = get_transforms()\n",
        "        self.is_train = is_train\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df_signal)\n",
        "\n",
        "    def gen_sample(self, signal, noise, signal_strength):\n",
        "        noise = np.array(Image.open(noise))\n",
        "        if signal:\n",
        "            signal = np.array(Image.open(signal))\n",
        "            noise = noise + signal_strength * signal\n",
        "        if self.is_train and self.gaussian_noise > 0:\n",
        "            noise = noise + np.random.randn(*noise.shape) * GAUSSIAN_NOISE \n",
        "        noise = np.clip(noise, 0, 255).astype(np.uint8)\n",
        "        return self.transforms(noise)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        noise_files = self.df_noise.sample().files.values[0]        \n",
        "        sig_files = [None, None]\n",
        "        label = 0.\n",
        "        if np.random.random() < self.positive_rate:\n",
        "            sig_files = self.df_signal.sample().files.values[0]\n",
        "            label = 1.\n",
        "        signal_strength = np.random.uniform(self.signal_low, self.signal_high)                    \n",
        "        return np.concatenate(\n",
        "            [self.gen_sample(sig, noise, signal_strength) for sig, noise in zip(sig_files, noise_files)], axis=0\n",
        "        ), label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "74989adc",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-12-30T20:53:56.959678Z",
          "iopub.status.busy": "2022-12-30T20:53:56.959343Z",
          "iopub.status.idle": "2022-12-30T20:53:56.986423Z",
          "shell.execute_reply": "2022-12-30T20:53:56.985486Z"
        },
        "papermill": {
          "duration": 0.033562,
          "end_time": "2022-12-30T20:53:56.988421",
          "exception": false,
          "start_time": "2022-12-30T20:53:56.954859",
          "status": "completed"
        },
        "tags": [],
        "id": "74989adc"
      },
      "outputs": [],
      "source": [
        "def net_hog_features(img: np.array, dim: int = 257) ->np.array:    \n",
        "    img = np.transpose(img.cpu().numpy(), (1, 2, 0))\n",
        "    bins = np.linspace(0, 1, dim)\n",
        "    fd = skimage.feature.hog(\n",
        "        img, orientations=8, pixels_per_cell=(16, 16),\n",
        "        cells_per_block=(3, 3), visualize=False, multichannel=True\n",
        "    )\n",
        "    hist = np.histogram(fd, bins=bins)\n",
        "    return hist[0]\n",
        "\n",
        "\n",
        "# -> CONV/FC -> BatchNorm -> ReLu(or other activation) -> Dropout -> CONV/FC ->\n",
        "class Net(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        name_model: str = CFG.model,\n",
        "        dim: int = 256,\n",
        "        hog: bool = CFG.hog\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.model = timm.create_model(\n",
        "            name_model,\n",
        "            in_chans=2,\n",
        "            pretrained=True \n",
        "        )\n",
        "        self.dim = dim\n",
        "        self.hog = hog\n",
        "        if self.hog:\n",
        "            self.s = nn.Linear(1000+self.dim, 1)\n",
        "        else:\n",
        "            self.s = nn.Linear(1000, 1)\n",
        "        # print('Take version: ', self.s, 'dim: ', self.dim)\n",
        "\n",
        "    def forward(self, x): \n",
        "        x1  = self.model(x)\n",
        "        if not self.hog:\n",
        "            return self.s(x1)\n",
        "        tmp = []\n",
        "        for j in x:\n",
        "            tmp.append(\n",
        "                torch.tensor(net_hog_features(j, self.dim + 1), dtype=torch.float, \n",
        "            ).reshape(1, -1).to(DEVICE))\n",
        "        xx =  torch.cat(tmp, axis = 0)\n",
        "        xx = nn.functional.normalize(xx, p=2.0, dim = 1)\n",
        "        x1 = nn.functional.normalize(x1, p=2.0, dim = 1) \n",
        "        x3 = torch.cat((x1, xx), axis = 1)   \n",
        "        return self.s(x3)\n",
        "\n",
        "\n",
        "def train(\n",
        "    model: nn.Module,\n",
        "    loader: torch.utils.data.dataloader,\n",
        "    optimizer: Optional[torch.optim.Optimizer],\n",
        "    scheduler: Optional[torch.optim.lr_scheduler.LambdaLR],\n",
        "    epoch: int\n",
        ") -> None:\n",
        "    model.train()\n",
        "    pbar = tqdm(\n",
        "        loader,\n",
        "        desc=f\"Model Train, epoch: {epoch+1} \",\n",
        "        total=len(loader),\n",
        "        mininterval= len(loader)//20\n",
        "    )\n",
        "    scaler = torch.cuda.amp.GradScaler(enabled=CFG.apex)\n",
        "    for X, y in pbar:\n",
        "        optimizer.zero_grad()\n",
        "        with torch.autocast(enabled=CFG.apex):\n",
        "            y_ = model(X.to(DEVICE))\n",
        "            loss = torch.nn.functional.binary_cross_entropy_with_logits(\n",
        "                y_.squeeze(), y.to(DEVICE)\n",
        "            )\n",
        "        norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n",
        "        if CFG.apex:\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "        else:\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        if scheduler:\n",
        "            scheduler.step()\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(\n",
        "    model: nn.Module,\n",
        "    loader: torch.utils.data.dataloader,\n",
        "    epoch: int\n",
        ") -> tuple:\n",
        "    model.to(DEVICE)\n",
        "    model.eval()        \n",
        "    pred = []\n",
        "    target = []\n",
        "    pbar = tqdm(\n",
        "        loader,\n",
        "        desc=f\"Valid, epoch: {epoch+1} \",\n",
        "        total=len(loader),\n",
        "        mininterval= len(loader)//20\n",
        "    )\n",
        "    for X, y in pbar:\n",
        "        with torch.autocast(enabled=CFG.apex):\n",
        "            y_ = model(X.to(DEVICE))\n",
        "        pred.append(y_.cpu().squeeze())\n",
        "        target.append(y)\n",
        "    pred = torch.concat(pred)\n",
        "    target = torch.concat(target)\n",
        "    loss = torch.nn.functional.binary_cross_entropy_with_logits(\n",
        "        pred, target, reduction='none'\n",
        "    ).median().item()\n",
        "    return roc_auc_score(target, torch.sigmoid(pred)), loss\n",
        "    \n",
        "    \n",
        "def run_training(dim: int, fold: int = 0) -> None:\n",
        "    kfold = KFold(CFG.folds, shuffle=True, random_state=CFG.seed)\n",
        "    df_noise_train, df_noise_eval = None, None\n",
        "    for f, (tr, vl) in enumerate(kfold.split(df_noise)):\n",
        "        if f == fold:\n",
        "            tr_noise = df_noise.loc[tr]\n",
        "            vl_noise = df_noise.loc[vl]\n",
        "    df_signal_train, df_signal_eval = None, None\n",
        "    for f, (tr, vl) in enumerate(kfold.split(df_signal)):\n",
        "        if f == fold:\n",
        "            tr_signal = df_signal.loc[tr]\n",
        "            vl_signal = df_signal.loc[vl]\n",
        "    tr_data = G2Net_Dataset(\n",
        "        tr_noise,\n",
        "        tr_signal,\n",
        "        is_train=True\n",
        "    )\n",
        "    vl_data = G2Net_Dataset(\n",
        "        vl_noise,\n",
        "        vl_signal\n",
        "    )\n",
        "    tr_loader = torch.utils.data.DataLoader(\n",
        "        tr_data,\n",
        "        batch_size=CFG.batch,\n",
        "        num_workers=os.cpu_count(),\n",
        "        pin_memory=True\n",
        "    )\n",
        "    vl_loder = torch.utils.data.DataLoader(\n",
        "        vl_data,\n",
        "        batch_size=CFG.batch,\n",
        "        num_workers=os.cpu_count(),\n",
        "        pin_memory=True\n",
        "    )\n",
        "    # model = timm.create_model(CFG.model, pretrained=True, num_classes=1, in_chans=2, drop_rate=CFG.dropout)\n",
        "    # print('Load model: ',  model.__class__.__name__)\n",
        "    model = Net(dim)\n",
        "    model.to(DEVICE)\n",
        "    optim = torch.optim.Adam(model.parameters(), lr=CFG.lr)\n",
        "    scheduler = None\n",
        "    if CFG.one_cycle::\n",
        "        scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
        "            optimizer=optim,\n",
        "            max_lr=CFG.lr,\n",
        "            total_steps=int(len(tr_loader) * CFG.epochs),\n",
        "            pct_start=CFG.one_cycle_pct_start\n",
        "    )\n",
        "    max_auc = 0\n",
        "    for epoch in range(CFG.epochs):\n",
        "        train(model, tr_loader, optim, scheduler, epoch)\n",
        "        auc, loss = evaluate(model, vl_loader, epoch)\n",
        "        if auc > max_auc:\n",
        "            torch.save(model.state_dict(), f'model-f{fold}.tph')\n",
        "            max_auc = auc\n",
        "        print(f'val_loss: {loss}, val_auc: {auc}, val_max_auc: {max_auc}')\n",
        "    del model, tr_loader, vl_loder, tr_data, vl_data    \n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "import logging\n",
        "\n",
        "\n",
        "logger = logging.getLogger()\n",
        "logger.setLevel(logging.INFO)  # Setup the root logger.\n",
        "logger.addHandler(logging.FileHandler(\"optuna_log.log\", mode=\"w\"))\n",
        "\n",
        "optuna.logging.enable_propagation()  # Propagate logs to the root logger.\n",
        "optuna.logging.disable_default_handler()  # Stop showing logs in sys.stderr.\n",
        "\n",
        "def objective(trial: optuna.Trial):\n",
        "    # CELLS_BLOCK = trial.suggest_categorical('CELLS_BLOCK',[(3, 3), (4, 4), (5, 5)])\n",
        "    # ORIENTATION = trial.suggest_categorical('ORIENTATION',[7,8,9])\n",
        "    # PIXELS = trial.suggest_categorical('PIXELS',[(14, 14), (16, 16), (20, 20)])\n",
        "    # POSITIVE_RATE_GS = trial.suggest_categorical('POSITIVE_RATE_GS', [ 0.1, 0.25, 0.5])    \n",
        "    # NORM_META = trial.suggest_categorical('NORM_META', [True, False])\n",
        "    # NORM_MODEL = trial.suggest_categorical('NORM_MODEL', [True, False])\n",
        "    # VERSION = trial.suggest_categorical('VERSION', [\n",
        "    #         [False, False, True],\n",
        "    #         [True, False, False],\n",
        "    #         [False, True, False],\n",
        "    #         [False, False, False]]\n",
        "    # )\n",
        "    # DIM = trial.suggest_categorical('DIM', [8, 14, 16, 64, 96])\n",
        "    # OUT_DIM = trial.suggest_categorical('OUT_DIM', [1024, 512, 256, 128])\n",
        "    CFG.lr = trial.suggest_float('LR', 0.0001, 0.005, log=True)\n",
        "    CFG.dropout = trial.suggest_categorical('DROPOUT', [0., 0.1, 0.25, 0.3, 0.4, 0.5])\n",
        "    CFG.max_grad_norm = trial.suggest_float('MAX_GRAD_NORM', 1, 20)\n",
        "    CFG.epochs = int(trial.suggest_float('EPOCHS', 2, 4, step=1.))\n",
        "    CFG.gaussian_noise = trial.suggest_categorical('GAUSSIAN_NOISE', [0.,1., 2., 3.])\n",
        "    CFG.one_cycle_pct_start= trial.suggest_categorical('ONE_CYCLE_PCT_START', [0., 0.1, 0.2, 0.3])\n",
        "    CFG.model = trial.suggest_categorical('MODEL', ['tf_efficientnetv2_l'])\n",
        "    CFG.one_cycle = trial.suggest_categorical('ONE_CYCLE', [True, False])\n",
        "    return run_training(MODEL, 16)\n",
        "\n",
        "print(ONE_CYCLE_PCT_START, GAUSSIAN_NOISE, MAX_GRAD_NORM, DROPOUT, LR)\n",
        "study = optuna.create_study(direction='maximize')\n",
        "logger.info(\"Start optimization.\")\n",
        "study.optimize(objective, n_trials=60)\n",
        "with open(f\"optuna_log.log\") as f:\n",
        "    assert f.readline().startswith(\"A new study created\")\n",
        "    assert f.readline() == \"Start optimization.\\n\""
      ],
      "metadata": {
        "id": "_8GMiwh25Lsr"
      },
      "id": "_8GMiwh25Lsr",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 13067.965032,
      "end_time": "2022-12-31T00:30:35.768603",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2022-12-30T20:52:47.803571",
      "version": "2.3.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}