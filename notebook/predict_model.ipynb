{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPahsPawLEqke3aytWSuChB"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q timm\n",
        "!pip install -q git+https://github.com/PyFstat/PyFstat@python37"
      ],
      "metadata": {
        "id": "QI7hgZRNB07s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_7jmgD5-BlZo"
      },
      "outputs": [],
      "source": [
        "import os, gc, re, h5py, cv2\n",
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm.auto import tqdm\n",
        "import numpy as np, pandas as pd\n",
        "from collections import defaultdict\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "import timm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "\n",
        "import skimage\n",
        "from skimage import io\n",
        "\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "class CFG:\n",
        "    wandb=False\n",
        "    competition='G2Net'\n",
        "    model='inception_v4'\n",
        "    apex=False\n",
        "    max_grad_norm=1.36\n",
        "    seed=13\n",
        "    positive_rate=0.5\n",
        "    signal_low=0.2\n",
        "    signal_high=0.1\n",
        "    folds=10\n",
        "    lr=0.00056\n",
        "    dropout=0.25\n",
        "    epochs=3\n",
        "    gaussian_noise=2.\n",
        "    one_cycle_pct_start=0.1\n",
        "    one_cycle=True\n",
        "    batch=32\n",
        "    hog=True\n",
        "    dim=None"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def make_image(data: np.array) -> np.array:\n",
        "    tmp = np.abs(data[-360:, :])\n",
        "    tmp = tmp[:, :256]#.reshape(360, 512, 11).mean(axis=2)\n",
        "    # v2\n",
        "    tmp = tmp - tmp.mean()\n",
        "    tmp = tmp * 255 / tmp.std()\n",
        "    return tmp\n",
        "\n",
        "\n",
        "def make_data(name_file: str) -> dict:\n",
        "    r\"\"\"  \n",
        "    name_file: str name.hdf5\n",
        "    return: {id: str, freq: [], L1: [[], []], H1:[[], []]}    \n",
        "    \"\"\"\n",
        "    data = defaultdict(dict)\n",
        "    with h5py.File(path / name_file, \"r\") as f:\n",
        "        idk = list(f.keys())[0]\n",
        "        data[idk]['freq'] = np.array(f[idk]['frequency_Hz'])\n",
        "        for k in ['L1', 'H1']:\n",
        "            data[idk][k] = [np.array(f[idk][k]['SFTs']), np.array(f[idk][k]['timestamps_GPS'])]\n",
        "    return data\n",
        "\n",
        "\n",
        "def bin_noise(data: np.array, ts: np.array, bin: int = 256) -> list:\n",
        "    r\"\"\" Split data by by bin, mean all data between split index, or fill mean data\n",
        "    This idea get smooths results.\n",
        "        data: amplitudes\n",
        "        ts: time timestamps\n",
        "        bin: int\n",
        "    return: tuple    \n",
        "    \"\"\"\n",
        "    bin_size = (ts.max() - ts.min()) // bin\n",
        "    idx = np.searchsorted(ts, [ts[0] + bin_size * i for i in range(bin)])\n",
        "    global_noise = np.mean(np.abs(data))\n",
        "    return np.array(\n",
        "        [np.mean(np.abs(i)) if i.shape[1] > 0 else global_noise for i in np.array_split(data, idx[1:], axis=1)]\n",
        "    )\n",
        "\n",
        "\n",
        "def to_img(data: np.array, ts: np.array, bin: int = 256) -> np.array:\n",
        "    smooth_noise = bin_noise(data, ts)\n",
        "    img = make_image(smooth_noise)\n",
        "    img = np.clip(img, 0, 255).astype(np.uint8)\n",
        "    # print(np.min(img), np.max(img), np.mean(img), np.std(img))\n",
        "    return img\n",
        "\n",
        "\n",
        "def net_hog_features(img: np.array, dim: int = 257) ->np.array:    \n",
        "    img = np.transpose(img.cpu().numpy(), (1, 2, 0))\n",
        "    bins = np.linspace(0, 1, dim)\n",
        "    fd = skimage.feature.hog(\n",
        "        img, orientations=8, pixels_per_cell=(16, 16),\n",
        "        cells_per_block=(3, 3), visualize=False, multichannel=True\n",
        "    )\n",
        "    hist = np.histogram(fd, bins=bins)\n",
        "    return hist[0]\n",
        "\n",
        "\n",
        "class G2NETDataset(Dataset):\n",
        "    def __init__(self, df: pd.DataFarame, image_path: str) -> None:\n",
        "        self.df = df\n",
        "        self.image_path = image_path\n",
        "        self.transforms = get_transforms()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        id = self.df.iloc[index].id\n",
        "        h1 = self.transforms(Image.open(f'{self.image_path}/{id}_h1.png'))\n",
        "        l1 = self.transforms(Image.open(f'{self.image_path}/{id}_l1.png'))\n",
        "        return np.concatenate([h1, l1])\n",
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        name_model: str = CFG.model,\n",
        "        dim: int = CFG.dim,\n",
        "        hog: bool = CFG.hog\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.model = timm.create_model(\n",
        "            name_model,\n",
        "            in_chans=2,\n",
        "            pretrained=False \n",
        "        )\n",
        "        self.dim = dim\n",
        "        self.hog = hog\n",
        "        if self.hog:\n",
        "            self.s = nn.Linear(1000+self.dim, 1)\n",
        "        else:\n",
        "            self.s = nn.Linear(1000, 1)\n",
        "        # print('Take version: ', self.s, 'dim: ', self.dim)\n",
        "\n",
        "    def forward(self, x): \n",
        "        x1  = self.model(x)\n",
        "        if not self.hog:\n",
        "            return self.s(x1)\n",
        "        tmp = []\n",
        "        for j in x:\n",
        "            tmp.append(\n",
        "                torch.tensor(net_hog_features(j, self.dim + 1), dtype=torch.float, \n",
        "            ).reshape(1, -1).to(DEVICE))\n",
        "        xx =  torch.cat(tmp, axis = 0)\n",
        "        xx = nn.functional.normalize(xx, p=2.0, dim = 1)\n",
        "        x1 = nn.functional.normalize(x1, p=2.0, dim = 1) \n",
        "        x3 = torch.cat((x1, xx), axis = 1)   \n",
        "        return self.s(x3)\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(\n",
        "    model: nn.Module,\n",
        "    loader: torch.utils.data.dataloader\n",
        ") -> tuple:\n",
        "    model.to(DEVICE)\n",
        "    model.eval()        \n",
        "    pred = []\n",
        "    pbar = tqdm(\n",
        "        loader,\n",
        "        desc=f\"Test: \",\n",
        "        total=len(loader),\n",
        "        mininterval= len(loader)//20\n",
        "    )\n",
        "    for X in pbar:\n",
        "        with torch.autocast(enabled=CFG.apex):\n",
        "            y_ = model(X.to(DEVICE))\n",
        "        pred.append(y_.cpu().squeeze())\n",
        "    pred = torch.concat(pred)\n",
        "    return torch.sigmoid(pred).numpy()"
      ],
      "metadata": {
        "id": "nlmHKJSUB2ji"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p data/test_img\n",
        "for _, r in tqdm(df_test.iterrows(), total=len(df_test)):\n",
        "    if not os.path.exists(f'data/test_img/{r.id}_h1.png'):\n",
        "        data = make_data(f'/kaggle/input/g2net-detecting-continuous-gravitational-waves/test/{r.id}.hdf5')\n",
        "        h1 = to_img(data[r.id]['H1'][0], data[r.id]['H1'][1])\n",
        "        l1 = to_img(data[r.id]['L1'][0], data[r.id]['L1'][1])\n",
        "        cv2.imwrite(f'data/test_img/{r.id}_h1.png', h1)\n",
        "        cv2.imwrite(f'data/test_img/{r.id}_l1.png', l1)"
      ],
      "metadata": {
        "id": "16z765cnkWqh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test = G2NETDataset(df_test, paths)\n",
        "loader_test = torch.utils.data.DataLoader(\n",
        "    test,\n",
        "    batch_size=CFG.batch,\n",
        "    shuffle=False,\n",
        "    num_workers=os.cpu_count()\n",
        ")\n",
        "fold_preds = []\n",
        "for fold in range(CFG.folds):\n",
        "    model = Net()\n",
        "    model.load_state_dict(torch.load(f'/kaggle/input/efficientnetv2-m-hog/models/model-f{fold}.tph'))\n",
        "    preds = evaluate(model, loader_test)\n",
        "    fold_preds.append(preds)\n",
        "    del model, preds\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "preds = np.stack(fold_preds).squeeze().mean(axis=0)\n",
        "df_test['target'] = preds\n",
        "df_test.target.plot.hist()"
      ],
      "metadata": {
        "id": "2igqJf-8Ei7l"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}